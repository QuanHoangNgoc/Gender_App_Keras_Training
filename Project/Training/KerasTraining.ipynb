{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbaG75pgGG1n"
      },
      "source": [
        "## sprint0: global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cEUqAjdaTNLm"
      },
      "outputs": [],
      "source": [
        "#!pip install -q keras-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyUIy8pkOJyx",
        "outputId": "78737f52-7a52-4ac0-8236-36b814c9b69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n",
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "# import before\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWX6uktbGKC_",
        "outputId": "513be80a-042b-4609-83f8-4d2202169c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.23.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "# setting random_state\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN-YnlBsGx29"
      },
      "source": [
        "### libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TdCIFl0oGSZp"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as skl, sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "e0px7lZhGcWa"
      },
      "outputs": [],
      "source": [
        "# fix random_state\n",
        "def fixRandomState(fixed_state: int = RANDOM_STATE):\n",
        "  np.random.seed(fixed_state)\n",
        "  tf.random.set_seed(fixed_state)\n",
        "\n",
        "# exception\n",
        "def exception(requirement: bool, content):\n",
        "  if(requirement == False): raise ValueError(content)\n",
        "def catchException(ex: Exception):\n",
        "  print(type(ex), ex.args) \n",
        "  exception(False, ex)\n",
        "\n",
        "# message\n",
        "def mesVerbose(flag: bool, verbose, func_dir: str=\"\"):\n",
        "  if(flag == False): return\n",
        "  print(\"__verbose__:\", func_dir, verbose)\n",
        "def mesWarning(note, func_dir: str=\"\"):\n",
        "  print(\"__warning__:\", func_dir, str(note) + \"!\")\n",
        "\n",
        "# dynamic value config\n",
        "dynamic_value_config = defaultdict(lambda x: None)\n",
        "def encode_dvc(name: str) -> str:\n",
        "  name = name.lower()\n",
        "  return name.replace(\" \",\"_\")\n",
        "def add_dvc(name: str, value):\n",
        "  dynamic_value_config[encode_dvc(name)] = value\n",
        "def get_dvc(name: str):\n",
        "  value = dynamic_value_config[encode_dvc(name)]\n",
        "  exception(value != None, 'dvc is none')\n",
        "  return value\n",
        "def show_dvc():\n",
        "  mesVerbose(True, \"\", \" > show_dvc:\")\n",
        "  for key, value in dynamic_value_config.items():\n",
        "    print(f'{key}: {value}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYzy7wC7G5Z_"
      },
      "source": [
        "### view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KuTHIn-1Gm-O"
      },
      "outputs": [],
      "source": [
        "class View:\n",
        "  # Singleton Pattern\n",
        "  _instance = None\n",
        "  def __new__(cls):\n",
        "    if cls._instance is None: cls._instance = super(View, cls).__new__(cls)\n",
        "    return cls._instance\n",
        "\n",
        "  def over(self, val) -> tuple:\n",
        "    try:\n",
        "      mesVerbose(True, (type(val), val.shape), \"View > over:\")\n",
        "    except:\n",
        "      mesVerbose(True, (type(val), \"no shape\"), \"View > over:\")\n",
        "\n",
        "  def plotModel(self, model, show_name: bool=False):\n",
        "    return keras.utils.plot_model(model,\n",
        "      show_layer_names=show_name, show_layer_activations=True,\n",
        "      show_shapes=True, show_dtype=True)\n",
        "\n",
        "  def debugModel(self, model):\n",
        "    model.summary(show_trainable=True)\n",
        "\n",
        "view = View()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u27ryFd9HO4_"
      },
      "source": [
        "## sprint1: using available model from keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qotlOcXE3dv"
      },
      "source": [
        "### const value "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TjV-VYQTExGx"
      },
      "outputs": [],
      "source": [
        "# const data\n",
        "IMAGE_TARGET_SIZE = (64, 64)\n",
        "IMAGE_COLOR_MODE = 'rgb'\n",
        "INPUT_SHAPE = (64, 64, 3)\n",
        "CLASS_MODE = 'binary'\n",
        "OUTPUT_SHAPE = (1)\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Zb0pkI4RCWEK"
      },
      "outputs": [],
      "source": [
        "DIR_TRAIN = '/content/Ipynb_Pipeline_Guide/Train'\n",
        "DIR_VALID = '/content/Ipynb_Pipeline_Guide/Validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Abi71DI1kmSE"
      },
      "outputs": [],
      "source": [
        "# const checkpoint\n",
        "NAME_MODEL_INIT = 'model_after_init_state.keras'\n",
        "NAME_MODEL_EPOCH = 'model_after_epoch_{epoch}.keras'\n",
        "NAME_MODEL_TEST = 'model_after_test.keras'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_nvxaLoC0f3"
      },
      "source": [
        "### dataflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kq3EcM7hBZHd"
      },
      "outputs": [],
      "source": [
        "#%rm -rf Ipynb_Pipeline_Guide_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6Ztuc_c8xuQ",
        "outputId": "ee571220-fcbe-4413-c74e-e0fbf124407c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Ipynb_Pipeline_Guide' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b master https://github.com/QuanHoangNgoc/Ipynb_Pipeline_Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqlhI0RRLQfi"
      },
      "source": [
        "### ImageLoading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "JuhZU7C6LB3a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class ImageLoading:\n",
        "  def __init__(self, batch_size: int, class_mode: str,\n",
        "              target_size: tuple, color_mode='rgb',\n",
        "              seed: int = RANDOM_STATE):\n",
        "    self.batch_size, self.class_mode = batch_size, class_mode\n",
        "    self.target_size, self.color_mode = target_size, color_mode\n",
        "    self.seed = seed\n",
        "\n",
        "  def convertToTFDataset(self, data_generator):\n",
        "    s, s2 = INPUT_SHAPE, OUTPUT_SHAPE\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "      lambda: data_generator,\n",
        "      output_signature=(\n",
        "          tf.TensorSpec(shape=(None, s[0], s[1], s[2]), dtype=tf.float32),\n",
        "          tf.TensorSpec(shape=(None, ), dtype=tf.float32)\n",
        "      )\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "  def getGenerator(self, split: float, rng: bool):\n",
        "    gen = ImageDataGenerator(validation_split=split, rescale = 1./255)\n",
        "    if(rng):\n",
        "      gen = ImageDataGenerator(validation_split=split, rescale = 1./255,\n",
        "        rotation_range=25, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "        horizontal_flip=True, fill_mode='nearest')\n",
        "    return gen\n",
        "\n",
        "  def flowBatches(self, dir: str, split: float=0.999, rng: bool=False):\n",
        "    gen = self.getGenerator(split, rng)\n",
        "    data_gen = gen.flow_from_directory(dir, subset='validation',\n",
        "      batch_size=self.batch_size, class_mode=self.class_mode, target_size=self.target_size, color_mode=self.color_mode,\n",
        "      seed=self.seed)\n",
        "    view.over(data_gen)\n",
        "    return data_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kuK2AVz0iPb9"
      },
      "outputs": [],
      "source": [
        "loading = ImageLoading(BATCH_SIZE, CLASS_MODE, IMAGE_TARGET_SIZE, IMAGE_COLOR_MODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBAmX7BDiW1F",
        "outputId": "a6ec76d0-3d6a-41e3-a7ca-df974376c44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7999 images belonging to 2 classes.\n",
            "__verbose__: View > over: (<class 'keras.src.preprocessing.image.DirectoryIterator'>, 'no shape')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.image.DirectoryIterator at 0x79d9f0a5cc40>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loading.flowBatches(DIR_TRAIN, 0.05, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ2Hw38bnUkH",
        "outputId": "ccff818f-4444-4aa6-d314-9bbe7856556c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1129 images belonging to 2 classes.\n",
            "__verbose__: View > over: (<class 'keras.src.preprocessing.image.DirectoryIterator'>, 'no shape')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.image.DirectoryIterator at 0x79d9f0a5d8d0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loading.flowBatches(DIR_VALID, 0.05, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBbYVloQFzXu"
      },
      "source": [
        "### base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "wPVlgYb7HVlp"
      },
      "outputs": [],
      "source": [
        "# base model VGG16\n",
        "base_model = keras.applications.VGG16(input_shape=INPUT_SHAPE, include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7sJCt_qlF2nx"
      },
      "outputs": [],
      "source": [
        "# freeze base model\n",
        "add_dvc('number_base_unfreeze', -5)\n",
        "for layer in base_model.layers[:get_dvc('number base unfreeze')]:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zQCV15-_MFt",
        "outputId": "a407e6e2-c730-4881-ad3b-ac6b3f44820e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__verbose__:  > show_dvc: \n",
            "number_base_unfreeze: -5\n"
          ]
        }
      ],
      "source": [
        "show_dvc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgDOhSnKzOu6"
      },
      "source": [
        "### main model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5jD9EST_Ga-J"
      },
      "outputs": [],
      "source": [
        "# main model\n",
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, BatchNormalization, Flatten, Dense, MaxPooling2D\n",
        "\n",
        "# Building Model\n",
        "model=Sequential()\n",
        "model.add(base_model.input)\n",
        "model.add(base_model)\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(.1))\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(.1))\n",
        "model.add(Conv2D(384, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(.1))\n",
        "model.add(Conv2D(384, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(.1))\n",
        "model.add(Conv2D(500, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(2, strides=(2,2), padding='same'))\n",
        "# Add new layers\n",
        "FC = 2048\n",
        "E = 1\n",
        "model.add(Flatten())\n",
        "model.add(Dense(FC , activation='relu'))\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(Dense(FC, activation='relu'))\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(Dense(FC, activation='relu'))\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(Dense(E, activation='sigmoid'))\n",
        "# debug model\n",
        "# view.debugModel(model)\n",
        "# view.plotModel(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhsDYUOLHe5p"
      },
      "source": [
        "### ModelSaving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "gKauTUnfvCA7"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "class ModelSaving:\n",
        "  def __init__(self, name_init: str, name_epoch: str, name_test: str):\n",
        "    self.name_init, self.name_epoch, self.name_test = name_init, name_epoch, name_test\n",
        "    self.mcp = ModelCheckpoint(name_epoch)\n",
        "\n",
        "  def getModelCheckpoint(self):\n",
        "    return self.mcp\n",
        "\n",
        "  def getModelFromInitSatte(self):\n",
        "    return keras.saving.load_model(self.name_init)\n",
        "  def getModelFromEpoch(self, id: int = -1):\n",
        "    if(id == -1):\n",
        "      return keras.saving.load_model(self.name_epoch)\n",
        "    return keras.saving.load_model(self.name_epoch.format(epoch = id))\n",
        "\n",
        "  def saveInitState(self, model):\n",
        "    return model.save(self.name_init)\n",
        "  def saveTestedModel(self, model):\n",
        "    return model.save(self.name_test)\n",
        "\n",
        "saving = ModelSaving(NAME_MODEL_INIT, NAME_MODEL_EPOCH, NAME_MODEL_TEST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVocoMOoTgHo"
      },
      "source": [
        "### ModelPrint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bCog4N7PTtWM"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "# customize engineering Callback\n",
        "class ModelPrint(Callback):\n",
        "  def __init__(self, big_validation, epoch_per_print: int=10):\n",
        "    super().__init__()\n",
        "    self.data_out_sample =  big_validation\n",
        "    self.epp = epoch_per_print\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if not hasattr(self, 'model'):\n",
        "      raise ValueError(\"callback can not access into model\")\n",
        "\n",
        "    if(epoch % self.epp == 0):\n",
        "      mesVerbose(True, self.model.evaluate(self.data_out_sample), \"ModelPrint > on_epoch_end:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AWBFvZFaJyJ"
      },
      "source": [
        "### compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nGIv4-MLP8",
        "outputId": "2357ddfc-bf36-463a-a8b5-5ffa353999c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "____________________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   Trainable  \n",
            "============================================================================\n",
            " vgg16 (Functional)          (None, 2, 2, 512)         1471468   Y          \n",
            "                                                       8                    \n",
            "                                                                            \n",
            " dropout_8 (Dropout)         (None, 2, 2, 512)         0         Y          \n",
            "                                                                            \n",
            " conv2d_5 (Conv2D)           (None, 2, 2, 512)         2359808   Y          \n",
            "                                                                            \n",
            " batch_normalization_5 (Bat  (None, 2, 2, 512)         2048      Y          \n",
            " chNormalization)                                                           \n",
            "                                                                            \n",
            " dropout_9 (Dropout)         (None, 2, 2, 512)         0         Y          \n",
            "                                                                            \n",
            " conv2d_6 (Conv2D)           (None, 2, 2, 128)         589952    Y          \n",
            "                                                                            \n",
            " batch_normalization_6 (Bat  (None, 2, 2, 128)         512       Y          \n",
            " chNormalization)                                                           \n",
            "                                                                            \n",
            " dropout_10 (Dropout)        (None, 2, 2, 128)         0         Y          \n",
            "                                                                            \n",
            " conv2d_7 (Conv2D)           (None, 2, 2, 384)         442752    Y          \n",
            "                                                                            \n",
            " batch_normalization_7 (Bat  (None, 2, 2, 384)         1536      Y          \n",
            " chNormalization)                                                           \n",
            "                                                                            \n",
            " dropout_11 (Dropout)        (None, 2, 2, 384)         0         Y          \n",
            "                                                                            \n",
            " conv2d_8 (Conv2D)           (None, 2, 2, 384)         1327488   Y          \n",
            "                                                                            \n",
            " batch_normalization_8 (Bat  (None, 2, 2, 384)         1536      Y          \n",
            " chNormalization)                                                           \n",
            "                                                                            \n",
            " dropout_12 (Dropout)        (None, 2, 2, 384)         0         Y          \n",
            "                                                                            \n",
            " conv2d_9 (Conv2D)           (None, 2, 2, 500)         1728500   Y          \n",
            "                                                                            \n",
            " batch_normalization_9 (Bat  (None, 2, 2, 500)         2000      Y          \n",
            " chNormalization)                                                           \n",
            "                                                                            \n",
            " max_pooling2d_1 (MaxPoolin  (None, 1, 1, 500)         0         Y          \n",
            " g2D)                                                                       \n",
            "                                                                            \n",
            " flatten_1 (Flatten)         (None, 500)               0         Y          \n",
            "                                                                            \n",
            " dense_4 (Dense)             (None, 2048)              1026048   Y          \n",
            "                                                                            \n",
            " dropout_13 (Dropout)        (None, 2048)              0         Y          \n",
            "                                                                            \n",
            " dense_5 (Dense)             (None, 2048)              4196352   Y          \n",
            "                                                                            \n",
            " dropout_14 (Dropout)        (None, 2048)              0         Y          \n",
            "                                                                            \n",
            " dense_6 (Dense)             (None, 2048)              4196352   Y          \n",
            "                                                                            \n",
            " dropout_15 (Dropout)        (None, 2048)              0         Y          \n",
            "                                                                            \n",
            " dense_7 (Dense)             (None, 1)                 2049      Y          \n",
            "                                                                            \n",
            "============================================================================\n",
            "Total params: 30591621 (116.70 MB)\n",
            "Trainable params: 22952541 (87.56 MB)\n",
            "Non-trainable params: 7639080 (29.14 MB)\n",
            "____________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# compile\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "LR_ALPHA = 0.001\n",
        "model.compile(optimizer=Adam(LR_ALPHA), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "view.debugModel(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "yWP5LyFaadmj"
      },
      "outputs": [],
      "source": [
        "saving.saveInitState(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2HI8_cITu7P"
      },
      "source": [
        "## sprint2: fitting and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "VjIDnxdeLich"
      },
      "outputs": [],
      "source": [
        "add_dvc('split_flow_from_dir', 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itlQ6Jb9tUmG",
        "outputId": "843fc896-61d7-4647-91fb-4fb50a5e0131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7999 images belonging to 2 classes.\n",
            "__verbose__: View > over: (<class 'keras.src.preprocessing.image.DirectoryIterator'>, 'no shape')\n"
          ]
        }
      ],
      "source": [
        "train_data_gen = loading.flowBatches(DIR_TRAIN, get_dvc('split_flow_from_dir'), True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWSs-ZVouCUK",
        "outputId": "3e9ed911-9438-4af3-c0bb-c9ecce9c77cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1129 images belonging to 2 classes.\n",
            "__verbose__: View > over: (<class 'keras.src.preprocessing.image.DirectoryIterator'>, 'no shape')\n"
          ]
        }
      ],
      "source": [
        "valid_data_gen = loading.flowBatches(DIR_VALID, get_dvc('split_flow_from_dir'), False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzezNCR2vLgB",
        "outputId": "d52479e6-bb7a-4fe4-a9d3-b38b4f17445b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 11299 images belonging to 2 classes.\n",
            "__verbose__: View > over: (<class 'keras.src.preprocessing.image.DirectoryIterator'>, 'no shape')\n"
          ]
        }
      ],
      "source": [
        "big = loading.flowBatches(DIR_VALID, 0.5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6q1JayLGURiJ"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "add_dvc('epochs', epochs)\n",
        "ratio = 1.0\n",
        "add_dvc('ratio_bpe', ratio)\n",
        "full_spe = 125\n",
        "full_vs = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCmsuBmtQEKL",
        "outputId": "a26131d1-529d-4e8f-b7f4-de46adb42b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.3 µs\n"
          ]
        }
      ],
      "source": [
        "%time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f48hnVPjZW78"
      },
      "source": [
        "- training: block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl4gN_mxZT7d"
      },
      "outputs": [],
      "source": [
        "# hist = model.fit(train_data_gen,\n",
        "#                   callbacks=[saving.getModelCheckpoint(), ModelPrint(big, 10)],\n",
        "#                   epochs=epochs, steps_per_epoch=ratio * full_spe, verbose=1,\n",
        "#                   validation_data=valid_data_gen, validation_steps=ratio * full_vs, validation_freq=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb4E0HHwiX4O"
      },
      "source": [
        "- testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7JqPhTA6QAo",
        "outputId": "f2b3a204-0788-452d-d045-2366036bc615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22596 images belonging to 2 classes.\n",
            "__verbose__: View > over: (<class 'keras.src.preprocessing.image.DirectoryIterator'>, 'no shape')\n"
          ]
        }
      ],
      "source": [
        "big = loading.flowBatches(DIR_VALID, split=0.99999, rng=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrHHRYe46j_3",
        "outputId": "e4fab1c6-0375-4360-a7c4-ae67206c4463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "354/354 [==============================] - 1012s 3s/step - loss: 0.4092 - accuracy: 0.8729\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.40917304158210754, 0.8728535771369934]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(big)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpXgoJCvidp1"
      },
      "source": [
        "- deploy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKBafLuIeTKG",
        "outputId": "98d9beaf-7eb5-4351-c7a8-8ead2f0006b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('model321.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOEekM0of2k2",
        "outputId": "b641c324-0352-4615-8611-1c8b787e6b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image input:\n",
            "(64, 64, 3)\n",
            "(1, 64, 64, 3) <class 'numpy.ndarray'>\n",
            "(1, 64, 64, 3) <class 'numpy.ndarray'>\n",
            "predict:\n",
            "1/1 [==============================] - 0s 312ms/step\n",
            "[[0.9048627]]\n",
            "This is a male\n",
            "now: 2024-01-29 14:01:41.932564\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image\n",
        "from datetime import datetime\n",
        "\n",
        "image_path = \"/content/160095.jpg\"\n",
        "INPUT_SIZE = (64, 64)\n",
        "\n",
        "print(\"image input:\")\n",
        "imge = image.load_img(image_path, target_size=(64, 64))\n",
        "x = image.img_to_array(imge)\n",
        "print(x.shape)\n",
        "x = np.expand_dims(x, axis=0) / 255\n",
        "print(x.shape, type(x))\n",
        "x = np.vstack([x])\n",
        "print(x.shape, type(x))\n",
        "\n",
        "print(\"predict:\")\n",
        "classes = model.predict(x, batch_size=1)\n",
        "print(classes)\n",
        "if classes[0]>0.5: print(\"This is a male\")\n",
        "else: print( \"This is a female\")\n",
        "\n",
        "print(\"now:\", datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB-VHbejgXAK",
        "outputId": "244f4910-f19e-4b0a-ab3e-567fa0f3e3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 57s 3s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.4368938e-08],\n",
              "       [1.1668251e-05],\n",
              "       [1.6284207e-01],\n",
              "       ...,\n",
              "       [3.1622306e-01],\n",
              "       [3.5077417e-07],\n",
              "       [1.6226870e-05]], dtype=float32)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(valid_data_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQLT9o6qHKb3"
      },
      "source": [
        "## end"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
